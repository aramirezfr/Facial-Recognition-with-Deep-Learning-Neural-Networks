{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2Bw/X++qhoRFfI3FKFGqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aramirezfr/Facial-Recognition-with-Deep-Learning-Neural-Networks/blob/master/Facial_Recognition_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation:"
      ],
      "metadata": {
        "id": "WXM1aWkhm0jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "aOX85op8mwq6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------"
      ],
      "metadata": {
        "id": "WO0o0U5YXj01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Face Dataset:"
      ],
      "metadata": {
        "id": "Prk3I2UUXlBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will be using the face dataset to train my model. I need to set the face dataset as the positive outcome of the model.\n",
        "I will also use the object dataset as the negative outcome."
      ],
      "metadata": {
        "id": "U3x6CSc-Xr8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn3ySETW1SKL",
        "outputId": "fca95904-cd9a-46fc-8f76-4d81a390de25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/lfw-dataset\n",
            "License(s): other\n",
            "lfw-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "#Downloading the data file from Kaggle\n",
        "#!kaggle datasets download -d jessicali9530/lfw-dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the data folder\n",
        "#!unzip lfw-dataset.zip -d data"
      ],
      "metadata": {
        "id": "bomKOPb3mqHQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the root directory you want to start from\n",
        "face_root_dir = 'data/lfw-deepfunneled/lfw-deepfunneled/'\n",
        "\n",
        "#list to store all jpeg file paths\n",
        "face_jpg_files = []\n",
        "\n",
        "#walk the directory tree\n",
        "for dirpath, dirnames, files in os.walk(face_root_dir):\n",
        "    for file in files:\n",
        "        # Check if the file ends with .jpg\n",
        "        if file.endswith('.jpg'):\n",
        "            # Construct the full file path\n",
        "            full_path = os.path.join(dirpath, file)\n",
        "            # Append to the list\n",
        "            face_jpg_files.append(full_path)\n",
        "\n",
        "#print all found jpg file paths\n",
        "#for jpg_file in face_jpg_files:\n",
        " #   print(jpg_file)"
      ],
      "metadata": {
        "id": "A7LcJ1CMnqOd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(face_jpg_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy8ljCWCsqrm",
        "outputId": "a8e8b9ab-6442-4bc9-bf35-2efc18ba0b89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13233"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------"
      ],
      "metadata": {
        "id": "rPOlTOORKS6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Objects Dataset"
      ],
      "metadata": {
        "id": "phVeqNX8KUhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the data file from Kaggle of the objects\n",
        "#!kaggle datasets download -d akash2sharma/tiny-imagenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJaZz9yDI9XE",
        "outputId": "0a02f5f7-f1af-4abd-d0e4-b5ecbe89ce39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/akash2sharma/tiny-imagenet\n",
            "License(s): unknown\n",
            "tiny-imagenet.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the data folder\n",
        "#!unzip tiny-imagenet.zip -d data"
      ],
      "metadata": {
        "id": "xGnDSgQWLDD4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_root_dir = 'data/tiny-imagenet-200/'\n",
        "object_jpg_files = []\n",
        "\n",
        "#walk the tiny objects directory tree\n",
        "for dirpath, dirnames, files in os.walk(object_root_dir):\n",
        "    for file in files:\n",
        "        # Check if the file ends with .JPEG\n",
        "        if file.endswith('.JPEG'):\n",
        "            # Construct the full file path\n",
        "            full_path = os.path.join(dirpath, file)\n",
        "            # Append to the list\n",
        "            object_jpg_files.append(full_path)\n",
        "#print all found jpg file paths\n",
        "#for jpg_file in object_jpg_files:\n",
        "#  print(jpg_file)"
      ],
      "metadata": {
        "id": "Chyk1puV7Nh2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(object_jpg_files)"
      ],
      "metadata": {
        "id": "CVsNOzR8DzIg",
        "outputId": "0956a6cb-8aa5-44c6-e19d-45cfe8e25cb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------"
      ],
      "metadata": {
        "id": "kB4v0ifnZ9Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming face_jpg_files contains paths to all face images\n",
        "# And object_jpg_files contains paths to all object images\n",
        "\n",
        "# Create labels for each set\n",
        "face_labels = [1] * len(face_jpg_files)  # Positive class\n",
        "object_labels = [0] * len(object_jpg_files)  # Negative class\n",
        "\n",
        "# Combine lists and labels\n",
        "all_files = face_jpg_files + object_jpg_files\n",
        "all_labels = face_labels + object_labels\n",
        "\n",
        "# Convert to TensorFlow Dataset\n",
        "files_ds = tf.data.Dataset.from_tensor_slices(all_files)\n",
        "labels_ds = tf.data.Dataset.from_tensor_slices(all_labels)\n",
        "dataset = tf.data.Dataset.zip((files_ds, labels_ds))\n",
        "\n",
        "# Define the target image size\n",
        "img_height = 128  # or another size that fits your model and resources\n",
        "img_width = 128\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "    image /= 255.0  # Normalize to [0,1]\n",
        "    return image, label\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Apply the preprocessing function\n",
        "dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Prepare for training\n",
        "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "K7kHVhqlhSTx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming all_files and all_labels are your image paths and labels\n",
        "all_files = np.array(all_files)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Assuming all_files and all_labels are your image paths and labels\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    all_files, all_labels, test_size=0.3, random_state=42, stratify=all_labels\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Resulting proportions:\n",
        "# X_train: 70% of the total data\n",
        "# X_val: 15% of the total data\n",
        "# X_test: 15% of the total data"
      ],
      "metadata": {
        "id": "3UxbapYBqH9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training set: {len(X_train)} images\")\n",
        "print(f\"Validation set: {len(X_val)} images\")\n",
        "print(f\"Test set: {len(X_test)} images\")"
      ],
      "metadata": {
        "id": "8Tal3WK_qb-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example for creating a TensorFlow Dataset for training\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Similarly, create validation and test datasets\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "val_dataset = val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "b-sCCp9Xqcnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('data/tiny-imagenet-200/tiny-imagenet-200', ignore_errors=True)"
      ],
      "metadata": {
        "id": "_jt5i3GytWx2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3GFNm4ngqbK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths to your datasets\n",
        "face_dir = 'path/to/face/dataset/'\n",
        "object_dirs = ['path/to/object/dataset1/', 'path/to/object/dataset2/']\n",
        "\n",
        "# Collect all face image paths and label them as 1 (positive)\n",
        "face_images = glob.glob(os.path.join(face_dir, '*.jpg'))\n",
        "face_labels = [1] * len(face_images)\n",
        "\n",
        "# Collect all object image paths and label them as 0 (negative)\n",
        "object_images = []\n",
        "for obj_dir in object_dirs:\n",
        "    object_images.extend(glob.glob(os.path.join(obj_dir, '*.jpg')))\n",
        "object_labels = [0] * len(object_images)\n",
        "\n",
        "# Combine face and object datasets\n",
        "all_images = face_images + object_images\n",
        "all_labels = face_labels + object_labels\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Shuffle and split the data into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(all_images, all_labels, test_size=0.3, random_state=42, stratify=all_labels)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} images\")\n",
        "print(f\"Validation set: {len(X_val)} images\")\n",
        "print(f\"Test set: {len(X_test)} images\")\n",
        "Key Points:\n",
        "Labels: 1 for face images and 0 for object images.\n",
        "Stratification: Using stratify=all_labels ensures that the split maintains the same proportion of face and object images in each subset, which is important for balanced datasets.\n",
        "Data Loading: Ensure you have a function to load the images when feeding them to the model (e.g., using TensorFlow's tf.data API or PyTorch's DataLoader).\n",
        "Training the Model:\n",
        "When training your model, ensure it is set up for binary classification. Hereâ€™s a quick example using Keras:\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# Ensure you have a data pipeline to load X_train and y_train\n",
        "# model.fit(train_dataset, validation_data=val_dataset, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "# model.evaluate(test_dataset)\n",
        "Ensure your data pipeline correctly feeds the image paths and corresponding labels into your model during training."
      ],
      "metadata": {
        "id": "qiQMHbr0aAA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}